#!/usr/bin/env python3
"""
Constructor de Grafo basado en ART√çCULOS del C√≥digo del Trabajo

Estrategia:
1. Extrae cada art√≠culo del PDF
2. Identifica contexto (Libro, T√≠tulo, Cap√≠tulo, P√°rrafo)
3. Detecta referencias entre art√≠culos
4. Crea nodos por art√≠culo
5. Crea relaciones basadas en referencias

Output: JSON con estructura art√≠culo-c√©ntrica
"""

import sys
import json
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import timedelta
import time

sys.path.insert(0, str(Path(__file__).parent))

from services.rag_service import RAGService
from services import groq_service


class ArticleGraphBuilder:
    """Construye grafo de C√≥digo del Trabajo basado en Art√≠culos"""
    
    def __init__(self, pdf_path: str):
        self.pdf_path = pdf_path
        self.text = ""
        self.articles = {}  # {article_number: {number, title, content, context}}
        self.nodes = {}     # {article_number: node}
        self.edges = []     # Relaciones entre art√≠culos
        self.context_stack = {
            "libro": None,
            "titulo": None,
            "capitulo": None,
            "parrafo": None
        }
    
    def extract_pdf(self) -> bool:
        """Extrae texto del PDF"""
        print("\nüìñ Extrayendo texto del PDF...")
        try:
            self.text = RAGService.extract_text_from_pdf(self.pdf_path)
            print(f"‚úÖ {len(self.text):,} caracteres extra√≠dos")
            return True
        except Exception as e:
            print(f"‚ùå Error: {str(e)}")
            return False
    
    def parse_articles(self) -> bool:
        """
        Extrae art√≠culos del texto usando regex inteligente
        
        Detecta:
        - Art√≠culos numerados (Art. 1¬∞, Art. 2, etc.)
        - Art√≠culos con sufijos (Art. 15 bis, Art. 25 ter)
        - Contexto jer√°rquico (Libro, T√≠tulo, Cap√≠tulo, P√°rrafo)
        """
        print("\nüîç Extrayendo art√≠culos...")
        
        try:
            # Patrones para detectar estructura
            libro_pattern = r'(?:^|\n)\s*(?:LIBRO|Libro)\s+([IVX]+|[A-Z]+).*?(?:$|\n)'
            titulo_pattern = r'(?:^|\n)\s*(?:T√çTULO|T√≠tulo)\s+([IVX]+|[A-Z]+).*?(?:$|\n)'
            capitulo_pattern = r'(?:^|\n)\s*(?:CAP√çTULO|Cap√≠tulo)\s+([IVX]+|[A-Z]+).*?(?:$|\n)'
            parrafo_pattern = r'(?:^|\n)\s*(?:P√°rrafo|P√ÅRRAFO)\s+([0-9¬∞¬∫]+).*?(?:$|\n)'
            
            # Patr√≥n para art√≠culos: "Art. 1¬∞", "Art. 15 bis", "Art. 25 ter", etc.
            # Captura: Art. [n√∫mero][opcional sufijo como bis/ter]
            article_pattern = r'(?:^|\n)\s*(?:Art\.?|ART√çCULO)\s+(\d+)\s*(?:(bis|ter|qu√°ter|bis\s+A|bis\s+B))?\s*[.‚Äî\-]?\s*(.+?)(?=(?:\n\s*(?:Art\.?|ART√çCULO)\s+\d+|$))'
            
            # Extraer contexto
            libro_matches = re.finditer(libro_pattern, self.text, re.MULTILINE | re.IGNORECASE)
            titulo_matches = re.finditer(titulo_pattern, self.text, re.MULTILINE | re.IGNORECASE)
            capitulo_matches = re.finditer(capitulo_pattern, self.text, re.MULTILINE | re.IGNORECASE)
            
            # Construir mapa de posiciones para contexto
            context_positions = {}
            for match in libro_matches:
                context_positions[match.start()] = ('libro', match.group(1))
            for match in titulo_matches:
                context_positions[match.start()] = ('titulo', match.group(1))
            for match in capitulo_matches:
                context_positions[match.start()] = ('capitulo', match.group(1))
            
            # Extraer art√≠culos
            article_matches = re.finditer(article_pattern, self.text, re.MULTILINE | re.DOTALL)
            articles_found = 0
            
            for match in article_matches:
                article_num = match.group(1)
                suffix = match.group(2) or ""
                content = match.group(3).strip()
                
                # Normalizar n√∫mero
                if suffix:
                    article_id = f"{article_num} {suffix}".replace("\n", " ").strip()
                else:
                    article_id = article_num
                
                # Actualizar contexto basado en posici√≥n
                pos = match.start()
                for ctx_pos in sorted(context_positions.keys(), reverse=True):
                    if ctx_pos <= pos:
                        ctx_type, ctx_value = context_positions[ctx_pos]
                        self.context_stack[ctx_type] = ctx_value
                        break
                
                # Crear nodo del art√≠culo
                self.articles[article_id] = {
                    "number": article_id,
                    "numeric": article_num,
                    "content": content[:500],  # Primeros 500 caracteres
                    "full_text": content,
                    "context": {
                        "libro": self.context_stack["libro"],
                        "titulo": self.context_stack["titulo"],
                        "capitulo": self.context_stack["capitulo"],
                        "parrafo": self.context_stack["parrafo"]
                    }
                }
                articles_found += 1
            
            print(f"‚úÖ {articles_found} art√≠culos extra√≠dos")
            return True
        
        except Exception as e:
            print(f"‚ùå Error extrayendo art√≠culos: {str(e)}")
            return False
    
    def extract_article_references(self) -> bool:
        """
        Detecta referencias entre art√≠culos
        
        Busca patrones como:
        - "art√≠culo 15"
        - "Art. 20"
        - "conforme al art√≠culo 25"
        - "v√©ase el art√≠culo 30"
        """
        print("\nüîó Extrayendo referencias entre art√≠culos...")
        
        # Patr√≥n para encontrar referencias a art√≠culos
        # Busca: art/art√≠culo [n√∫mero] [sufijo opcional]
        ref_pattern = r'(?:art\.?|art√≠culo|v√©ase|conforme al|seg√∫n el?|aplicable el?)\s+(?:art√≠culo\s+)?(\d+)\s*(bis|ter|qu√°ter)?'
        
        references = {}  # {from_article: [to_articles]}
        
        for article_id, article_data in self.articles.items():
            content = article_data["full_text"]
            
            # Buscar referencias en este art√≠culo
            matches = re.finditer(ref_pattern, content, re.IGNORECASE)
            referred_articles = set()
            
            for match in matches:
                ref_num = match.group(1)
                ref_suffix = match.group(2) or ""
                
                if ref_suffix:
                    ref_id = f"{ref_num} {ref_suffix}".replace("\n", " ").strip()
                else:
                    ref_id = ref_num
                
                # Validar que el art√≠culo referenciado existe
                if ref_id in self.articles or ref_num in self.articles:
                    referred_articles.add(ref_id if ref_id in self.articles else ref_num)
            
            if referred_articles:
                references[article_id] = list(referred_articles)
        
        # Crear edges (relaciones)
        for from_article, to_articles in references.items():
            for to_article in to_articles:
                self.edges.append({
                    "source": from_article,
                    "target": to_article,
                    "relation": "references",
                    "weight": 0.8
                })
        
        print(f"‚úÖ {len(self.edges)} referencias encontradas")
        return True
    
    def extract_article_titles(self) -> bool:
        """
        Usa el LLM para extraer un t√≠tulo descriptivo para cada art√≠culo
        
        Esto mejora la legibilidad del grafo
        """
        print("\nü§ñ Extrayendo t√≠tulos de art√≠culos con LLM...")
        
        articles_to_process = list(self.articles.items())[:50]  # Procesar primeros 50
        
        for i, (article_id, article_data) in enumerate(articles_to_process):
            if i % 10 == 0:
                print(f"  [{i+1}/{len(articles_to_process)}] Procesando...")
            
            try:
                content_preview = article_data["content"][:300]
                
                prompt = f"""Dado este art√≠culo del C√≥digo del Trabajo, 
extrae un t√≠tulo conciso (m√°x 10 palabras) que describa su contenido principal.

Art√≠culo {article_id}:
{content_preview}

RESPONDE SOLO CON EL T√çTULO, sin explicaci√≥n."""
                
                title = groq_service.chat_simple(prompt).strip()
                # Limpiar resultado
                title = title.replace("**", "").replace('"', '').replace("'", '')[:50]
                
                self.articles[article_id]["title"] = title
                
            except Exception as e:
                # Usar primer p√°rrafo como t√≠tulo si falla
                first_line = article_data["content"].split('.')[0][:50]
                self.articles[article_id]["title"] = first_line
        
        print(f"‚úÖ T√≠tulos extra√≠dos")
        return True
    
    def build_nodes(self) -> bool:
        """Construye nodos del grafo desde art√≠culos"""
        print("\nüìà Construyendo nodos...")
        
        for article_id, article_data in self.articles.items():
            title = article_data.get("title", article_data["content"].split('.')[0])
            
            self.nodes[article_id] = {
                "id": article_id,
                "label": f"Art. {article_id}",
                "title": title,
                "type": "articulo",
                "content_preview": article_data["content"][:200],
                "context": article_data["context"],
                "description": f"Art√≠culo {article_id} - {title}"
            }
        
        print(f"‚úÖ {len(self.nodes)} nodos creados")
        return True
    
    def build_graph(self) -> Dict:
        """Construye estructura final del grafo"""
        return {
            "metadata": {
                "source": Path(self.pdf_path).name,
                "graph_type": "article-based",
                "total_articles": len(self.nodes),
                "total_references": len(self.edges),
                "articles_with_title": sum(1 for n in self.nodes.values() if "title" in n)
            },
            "nodes": list(self.nodes.values()),
            "edges": self.edges
        }
    
    def save_graph(self, output_path: str = None) -> str:
        """Guarda el grafo en JSON"""
        if output_path is None:
            pdf_name = Path(self.pdf_path).stem
            output_path = f"{pdf_name}_articles_graph.json"
        
        graph = self.build_graph()
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(graph, f, ensure_ascii=False, indent=2)
        
        print(f"\nüíæ Grafo guardado: {output_path}")
        return output_path
    
    def print_stats(self):
        """Imprime estad√≠sticas del grafo"""
        print("\n" + "="*70)
        print("üìä ESTAD√çSTICAS DEL GRAFO DE ART√çCULOS")
        print("="*70)
        
        print(f"\nüìà Tama√±o:")
        print(f"  ‚Ä¢ Art√≠culos (nodos): {len(self.nodes)}")
        print(f"  ‚Ä¢ Referencias (edges): {len(self.edges)}")
        
        print(f"\nüè∑Ô∏è  Contexto jer√°rquico:")
        libros = set(n.get("context", {}).get("libro") for n in self.nodes.values() if n.get("context"))
        titulos = set(n.get("context", {}).get("titulo") for n in self.nodes.values() if n.get("context"))
        
        print(f"  ‚Ä¢ Libros: {len([l for l in libros if l])}")
        print(f"  ‚Ä¢ T√≠tulos: {len([t for t in titulos if t])}")
        
        print(f"\n‚≠ê Art√≠culos m√°s referenciados:")
        ref_count = {}
        for edge in self.edges:
            target = edge["target"]
            ref_count[target] = ref_count.get(target, 0) + 1
        
        for article_id, count in sorted(ref_count.items(), key=lambda x: x[1], reverse=True)[:10]:
            title = self.nodes.get(article_id, {}).get("title", "?")
            print(f"  ‚Ä¢ Art. {article_id}: {count} referencias ({title})")
        
        print("\n" + "="*70 + "\n")


def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Construir grafo de C√≥digo del Trabajo basado en Art√≠culos"
    )
    parser.add_argument("pdf", help="Ruta al archivo PDF")
    parser.add_argument("-o", "--output", help="Ruta de salida para el JSON", default=None)
    parser.add_argument("-s", "--stats", action="store_true", help="Mostrar estad√≠sticas")
    parser.add_argument("--titles", action="store_true", help="Extraer t√≠tulos con LLM")
    
    args = parser.parse_args()
    
    if not Path(args.pdf).exists():
        print(f"‚ùå Error: PDF no encontrado: {args.pdf}")
        sys.exit(1)
    
    print("\n" + "="*70)
    print("üî® CONSTRUCTOR DE GRAFO - BASADO EN ART√çCULOS")
    print("="*70)
    
    process_start = time.time()
    
    builder = ArticleGraphBuilder(args.pdf)
    
    # Paso 1: Extraer PDF
    if not builder.extract_pdf():
        sys.exit(1)
    
    # Paso 2: Parsear art√≠culos
    if not builder.parse_articles():
        sys.exit(1)
    
    # Paso 3: Extraer referencias
    if not builder.extract_article_references():
        sys.exit(1)
    
    # Paso 4: Extraer t√≠tulos (opcional)
    if args.titles:
        builder.extract_article_titles()
    
    # Paso 5: Construir nodos
    if not builder.build_nodes():
        sys.exit(1)
    
    # Paso 6: Guardar
    output_file = builder.save_graph(args.output)
    
    total_time = time.time() - process_start
    total_td = timedelta(seconds=int(total_time))
    
    print("\n" + "="*70)
    print("‚úÖ GRAFO CREADO EXITOSAMENTE")
    print("="*70)
    print(f"\nüìÅ Archivo: {output_file}")
    print(f"üìä Art√≠culos: {len(builder.nodes)}")
    print(f"üîó Referencias: {len(builder.edges)}")
    print(f"‚è±Ô∏è  Tiempo: {total_td}\n")
    
    if args.stats:
        builder.print_stats()


if __name__ == "__main__":
    main()
